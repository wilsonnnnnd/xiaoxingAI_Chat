import tiktoken
import asyncio
import requests
import time
from typing import List, Dict

from config.config import (
    API_URL, HISTORY_LIMIT, MAX_HISTORY, MAX_HISTORY_ROUNDS, MAX_SUMMARY_TOKENS, PROMPT_PATH
)
from function.log.chat_logger import log_conversation
from function.emotion.emotion_utils import EmotionTracker, log_emotion_analysis
from function.audio.speech_utils import speak
from function.memory.memory_tools import analyze_input, recall_input
from function.memory.memory import Memory
from function.summary.summary_manager import load_latest_summary, summarize_and_store
from function.audio.speech_config_db import get_speech_config
from function.summary.scheduler_manager import (
    start_summary_scheduler_thread,
    start_speech_report_scheduler_thread
)

# åˆå§‹åŒ–æ¨¡å—å®ä¾‹
memory = Memory()
emotion_tracker = EmotionTracker()
chat_history = []


def truncate_text_by_tokens(text: str, max_tokens: int) -> str:
    enc = tiktoken.get_encoding("cl100k_base")
    tokens = enc.encode(text)
    if len(tokens) <= max_tokens:
        return text
    return enc.decode(tokens[:max_tokens]) + "..."


def build_prompt(
    user_input: str,
    system_prompt: str = "",
    history: List[Dict[str, str]] = [],
    summary: str = ""
) -> str:
    summary_text = ""
    if summary:
        summary = truncate_text_by_tokens(summary, MAX_SUMMARY_TOKENS)
        summary_text = f"\nğŸ“ æœ€è¿‘çš„å¯¹è¯æ€»ç»“ï¼ˆå°æ˜Ÿå·å·è®°ä¸‹æ¥çš„ï¼‰ï½ï¼š\n{summary}\n"

    trimmed_history = history[-MAX_HISTORY_ROUNDS:]
    history_text = "".join(
        f"ç”¨æˆ·ï¼š{entry['user']}\nå°æ˜Ÿï¼š{entry['bot']}\n" for entry in trimmed_history
    )

    return (
        system_prompt.strip()
        + summary_text
        + "\nğŸŒŸ ä¸‹é¢æ˜¯æˆ‘ä»¬åˆšåˆšçš„å¯¹è¯è®°å½•ï¼š\n"
        + history_text
        + f"ç”¨æˆ·ï¼š{user_input}\nå°æ˜Ÿï¼š"
    )


def ask_llama_ai(user_input: str, summary: str = "") -> str:
    try:
        with open(PROMPT_PATH, encoding="utf-8") as f:
            system_prompt = f.read()
    except Exception as e:
        print("[âš ï¸ åŠ è½½ç³»ç»Ÿæç¤ºå¤±è´¥]", e)
        system_prompt = ""

    prompt = build_prompt(user_input, system_prompt,
                          chat_history[-HISTORY_LIMIT:], summary)

    try:
        response = requests.post(API_URL, json={
            "prompt": prompt,
            "n_predict": 256,
            "temperature": 0.7,
            "top_k": 50,
            "top_p": 0.9,
            "repeat_penalty": 1.1,
            "stop": ["ç”¨æˆ·ï¼š"]
        }, timeout=60)

        result = response.json()
        return result.get("content", result.get("choices", [{}])[0].get("text", "")).strip()

    except Exception as e:
        print("[âŒ å°æ˜Ÿ AI æ¥å£å‡ºé”™]", e)
        return "æˆ‘å¥½åƒæ²¡è¿ä¸Šå¤§è„‘â€¦è¯·ç¨åå†è¯•ä¸€æ¬¡ã€‚"


async def main():
    start_summary_scheduler_thread(chat_history)
    start_speech_report_scheduler_thread()

    print("\nğŸŒŸ å°æ˜Ÿå·²å¯åŠ¨ï¼Œå¼€å§‹é™ªä½ èŠå¤©å•¦ï½")
    summary = load_latest_summary()

    while True:
        user_input = input("\nä½ ï¼š").strip()
        if user_input.lower() in ["exit", "quit", "é€€å‡º"]:
            print("ğŸ‘‹ å°æ˜Ÿä¸‹çº¿äº†ï¼Œå†è§ï½")
            break

        if any(kw in user_input.lower() for kw in ["æ€»ç»“", "æ¦‚æ‹¬", "åˆšåˆšèŠäº†ä»€ä¹ˆ"]):
            summary = summarize_and_store(chat_history)
            print("\nğŸ§  å°æ˜Ÿï¼ˆæ€»ç»“ï¼‰ï¼š", summary)
            continue

        # âœ… ä¼˜å…ˆå°è¯•è®°å¿†é€»è¾‘
        response = analyze_input(user_input, memory)

        # âœ… æƒ…ç»ªè¯†åˆ« + å†™å…¥å…³é”®è¯æƒ…ç»ª + æƒ…ç»ªæ—¥å¿—
        emotion, keyword = emotion_tracker.detect_emotion(user_input)

        if keyword:
            memory.save_emotion(keyword, emotion)

        log_emotion_analysis(user_input, emotion)

        if not emotion:
            emotion = "neutral"

        # âœ… å›å¿†é€»è¾‘
        if not response:
            response = recall_input(user_input, memory)

        # âœ… AI å›åº”
        if not response:
            start_time = time.time()
            response = ask_llama_ai(user_input, summary)
            end_time = time.time()
            print(f"[â±ï¸ å›å¤è€—æ—¶] {(end_time - start_time):.2f} ç§’")

        final_reply = response.strip()
        print("å°æ˜Ÿï¼š" + final_reply)

        # âœ… è®°å½•å¯¹è¯æ—¥å¿—ï¼ˆå«æƒ…ç»ªï¼‰
        log_conversation(user_input, final_reply, extra_fields={
            "emotion": emotion,
            "keyword": keyword or ""
        })

        # âœ… æƒ…ç»ªé©±åŠ¨è¯­éŸ³æ’­æ”¾
        try:
            speech_config = get_speech_config(emotion)
            await speak(
                final_reply,
                voice=speech_config.get("voice"),
                style=speech_config.get("style"),
                rate=speech_config.get("rate"),
                volume=speech_config.get("volume")
            )
        except Exception as e:
            print("[âŒ è¯­éŸ³åˆæˆå‡ºé”™]", e)

        # âœ… æ›´æ–°å†å²
        chat_history.append({"user": user_input, "bot": final_reply})
        if len(chat_history) > MAX_HISTORY:
            chat_history.pop(0)

        # âœ… è¾“å‡ºå½“å‰å¯¹è¯çš„æƒ…ç»ªç»Ÿè®¡
        print(emotion_tracker.get_summary())


if __name__ == "__main__":
    asyncio.run(main())
